{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of Predictive State Smoothing (PRESS)\n",
    "\n",
    "PRESS is a kernel smoothing technique for any type of predictive learning problem (classification, regression, ...).\n",
    "\n",
    "This notebook shows examples of how to use the main functionality for a regression and classification problem.  Core PRESS functionality and layers, though, can be used for any learning problem with non-standard activation functions.\n",
    "\n",
    "See also\n",
    "\n",
    "\n",
    "* Goerg (2018) *[Classification using Predictive State Smoothing (PRESS): A scalable kernel classifier for high-dimensional features with variable selection](https://research.google/pubs/pub46767/)*.\n",
    "\n",
    "* Goerg (2017) *[Predictive State Smoothing (PRESS): Scalable non-parametric regression for high-dimensional data with variable selection](https://research.google/pubs/pub46141/).*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "from os.path import dirname\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import logging\n",
    "import datetime\n",
    "parent_path = dirname(pathlib.Path(pathlib.Path(os.getcwd())))\n",
    "\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.insert(0, parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pypress.keras.layers' from '/home/georg/Projects/pypress/pypress/keras/layers.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pypress.keras import layers\n",
    "from pypress.keras import initializers\n",
    "from pypress.keras import regularizers\n",
    "from pypress import utils\n",
    "\n",
    "importlib.reload(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc helper functions\n",
    "from typing import Tuple, Any\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "def _get_loss_activation_metrics(y: pd.Series) -> Tuple[Any, Any, Any]:\n",
    "\n",
    "    if len(np.unique(y)) == 2:\n",
    "        act = \"sigmoid\"\n",
    "        loss_fn = \"binary_crossentropy\"\n",
    "        metrics = [tf.keras.metrics.AUC(curve=\"PR\", name=\"aupr\"), tf.keras.metrics.AUC(curve=\"ROC\", name=\"auc_roc\")]\n",
    "    else:\n",
    "        act = \"linear\"\n",
    "        loss_fn = \"mse\"\n",
    "        metrics = [tf.keras.metrics.mean_squared_error]\n",
    "        \n",
    "        if (y >= 0.).all():\n",
    "            act = \"softplus\"\n",
    "            loss_fn = \"mse\"\n",
    "\n",
    "    return (loss_fn, act, metrics)\n",
    "\n",
    "\n",
    "def _get_recommended_callbacks():\n",
    "    logdir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    print(logdir)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "    return [tf.keras.callbacks.EarlyStopping(patience=10),\n",
    "                             tensorboard_callback], logdir\n",
    "\n",
    "\n",
    "def _scale_df(X, scaler = None):\n",
    "    \n",
    "    if scaler is None:\n",
    "        scaler = RobustScaler()\n",
    "        scaler.fit(X)\n",
    "    return pd.DataFrame(scaler.transform(X), columns=X.columns, index=X.index), scaler\n",
    "\n",
    "\n",
    "def _train_test_scale(X, y):\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    X_train_s, scaler = _scale_df(X_train, None)\n",
    "    X_test_s, scaler = _scale_df(X_test, scaler)\n",
    "    \n",
    "    return (X_train, y_train, X_test, y_test), scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = housing[\"data\"], housing[\"target\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(X.corr(\"spearman\"))\n",
    "plt.show()\n",
    "sns.displot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[y < 5]\n",
    "y = y.loc[y < 5]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(X.corr(\"spearman\"))\n",
    "plt.show()\n",
    "sns.displot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data, sc = _train_test_scale(X, y)\n",
    "X_tr, y_tr, X_ts, y_ts = scaled_data\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn, act, metrics = _get_loss_activation_metrics(y_ts)\n",
    "print(act, loss_fn)\n",
    "\n",
    "feat_input = tf.keras.layers.Input(shape=(X_tr.shape[1],))\n",
    "\n",
    "feat_eng_layer = tf.keras.Sequential()\n",
    "feat_eng_layer.add(tf.keras.layers.Dense(30, \"relu\", kernel_regularizer=tf.keras.regularizers.L2(0.001)))\n",
    "feat_eng_layer.add(tf.keras.layers.Dropout(0.25))\n",
    "feat_eng_layer.add(tf.keras.layers.BatchNormalization())\n",
    "feat_eng_layer.add(tf.keras.layers.Dense(10, \"tanh\", kernel_regularizer=tf.keras.regularizers.L2(0.001)))\n",
    "feat_eng_layer.add(tf.keras.layers.Dropout(0.25))\n",
    "feat_eng_layer.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "hidden = feat_eng_layer(feat_input)\n",
    "eps_mapping = layers.PredictiveStateSimplex(n_states=5, activity_regularizer=regularizers.Uniform(l1=0.1),\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(0.001))\n",
    "pred_states = eps_mapping(hidden)\n",
    "state_mean_layer = layers.PredictiveStateMeans(units=1, activation=act)\n",
    "pred = state_mean_layer(pred_states)\n",
    "\n",
    "mod = tf.keras.Model(inputs=feat_input, outputs=pred)\n",
    "mod.compile(loss=loss_fn, optimizer=tf.keras.optimizers.Nadam(learning_rate=0.005),\n",
    "            metrics=metrics)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_mapping.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mean_layer.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = mod.fit(X_tr, y_tr, epochs=10, batch_size=32,\n",
    "                  validation_data=(X_ts, y_ts),\n",
    "                  callbacks=[],#_get_recommended_callbacks()\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.layers[-1].state_conditional_means.numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(eps_mapping.trainable_weights[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mod.predict(X)\n",
    "\n",
    "sns.jointplot(y, y_pred.ravel(), kind=\"hex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mapping = tf.keras.Model(inputs=feat_input, outputs=pred_states)\n",
    "print(X_ts.shape)\n",
    "pred_emb = state_mapping(X_ts.values).numpy()\n",
    "pred_emb = pd.DataFrame(pred_emb, index=X_ts.index)\n",
    "sns.heatmap(pred_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pred_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.col_normalize(pred_emb).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.state_size(pred_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.agg_data_by_state(pred_emb, X_ts).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(X.corr(\"spearman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True).plot.bar()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data, sc = _train_test_scale(X, y)\n",
    "X_tr, y_tr, X_ts, y_ts = scaled_data\n",
    "X_tr.shape, X_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn, act, metrics = _get_loss_activation_metrics(y)\n",
    "\n",
    "feat_input = tf.keras.layers.Input(shape=(X.shape[1],))\n",
    "\n",
    "feat_eng_layer = tf.keras.Sequential()\n",
    "feat_eng_layer.add(tf.keras.layers.Dense(50, \"selu\"))\n",
    "feat_eng_layer.add(tf.keras.layers.Dropout(0.25))\n",
    "feat_eng_layer.add(tf.keras.layers.BatchNormalization())\n",
    "feat_eng_layer.add(tf.keras.layers.Dense(30, \"tanh\"))\n",
    "feat_eng_layer.add(tf.keras.layers.Dropout(0.25))\n",
    "feat_eng_layer.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "hidden = feat_eng_layer(feat_input)\n",
    "pred_states = layers.PredictiveStateSimplex(n_states=5, activity_regularizer=regularizers.Uniform(10.))(hidden)\n",
    "pred = layers.PredictiveStateMeans(units=1, activation=act)(pred_states)\n",
    "\n",
    "mod = tf.keras.Model(inputs=feat_input, outputs=pred)\n",
    "mod.compile(loss=loss_fn, optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001),\n",
    "            metrics=metrics)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clbks, logdir_str = _get_recommended_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = mod.fit(X_tr, y_tr, epochs=30, \n",
    "                  validation_data=(X_ts, y_ts),\n",
    "                  callbacks=clbks,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir $logdir_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame({\"true\": y_ts, \"pred\": mod.predict(X_ts).ravel()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (precision_recall_curve, PrecisionRecallDisplay)\n",
    "precision, recall, _ = precision_recall_curve(preds[\"true\"], preds[\"pred\"])\n",
    "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mapping = tf.keras.Model(inputs=feat_input, outputs=pred_states)\n",
    "print(X_ts.shape)\n",
    "pred_emb = pd.DataFrame(state_mapping(X_ts.values).numpy(), index=X_ts.index)\n",
    "sns.heatmap(pred_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pred_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_state = utils.agg_data_by_state(X_ts, pred_emb)\n",
    "X_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.layers[-1].state_conditional_means.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.state_size(pred_emb, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pred_emb.dot(utils.col_normalize(pred_emb).transpose()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = lambda x: mod.predict(x)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "# build a Permutation explainer and explain the model predictions on the given dataset\n",
    "explainer = shap.explainers.Permutation(pred_fn, X_ts)\n",
    "explainer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(X_ts.iloc[:20])  # ~20sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of single `PRESS()` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tf.keras.Sequential()\n",
    "mod.add(layers.PredictiveStateSimplex(n_states=6, activity_regularizer=regularizers.Uniform(0.01), input_dim=X.shape[1]))\n",
    "mod.add(layers.PredictiveStateMeans(units=1, activation=\"sigmoid\"))\n",
    "mod.compile(loss=loss_fn, optimizer=tf.keras.optimizers.Nadam(learning_rate=0.01),\n",
    "            metrics=metrics)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.fit(X_tr, y_tr, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tf.keras.Sequential()\n",
    "mod.add(layers.PRESS(units=1, n_states=6, activation=\"sigmoid\", activity_regularizer=regularizers.DegreesOfFreedom(l1=0.1, df=2.), input_dim=X.shape[1]))\n",
    "mod.compile(loss=loss_fn, optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001),\n",
    "            metrics=metrics)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.fit(X_tr, y_tr, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " predictive_state_simplex_6   (None, 6)                186       \n",
      " (PredictiveStateSimplex)                                        \n",
      "                                                                 \n",
      " predictive_state_means_6 (P  (None, 1)                6         \n",
      " redictiveStateMeans)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 192\n",
      "Trainable params: 192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 1s 17ms/step - loss: 0.5911 - auc_pr: 0.9795 - val_loss: 0.4856 - val_auc_pr: 0.9975\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4933 - auc_pr: 0.9935 - val_loss: 0.4265 - val_auc_pr: 0.9995\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4241 - auc_pr: 0.9963 - val_loss: 0.3784 - val_auc_pr: 0.9997\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3693 - auc_pr: 0.9970 - val_loss: 0.3400 - val_auc_pr: 0.9997\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3257 - auc_pr: 0.9974 - val_loss: 0.3085 - val_auc_pr: 0.9996\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2898 - auc_pr: 0.9973 - val_loss: 0.2830 - val_auc_pr: 0.9997\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2606 - auc_pr: 0.9974 - val_loss: 0.2592 - val_auc_pr: 0.9997\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2353 - auc_pr: 0.9977 - val_loss: 0.2378 - val_auc_pr: 0.9997\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2139 - auc_pr: 0.9974 - val_loss: 0.2207 - val_auc_pr: 0.9997\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1957 - auc_pr: 0.9979 - val_loss: 0.2076 - val_auc_pr: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe22c614430>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import sklearn\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "X_s = sklearn.preprocessing.robust_scale(X)  # See demo.ipynb to properly scale X with train/test split\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from pypress.keras import layers\n",
    "from pypress.keras import regularizers\n",
    "\n",
    "mod = tf.keras.Sequential()\n",
    "# see layers.PRESS() for single layer wrapper\n",
    "mod.add(layers.PredictiveStateSimplex(\n",
    "            n_states=6,\n",
    "            activity_regularizer=regularizers.Uniform(0.01),\n",
    "            input_dim=X.shape[1]))\n",
    "mod.add(layers.PredictiveStateMeans(units=1, activation=\"sigmoid\"))\n",
    "mod.compile(loss=\"binary_crossentropy\",\n",
    "            optimizer=tf.keras.optimizers.Nadam(learning_rate=0.01),\n",
    "            metrics=[tf.keras.metrics.AUC(curve=\"PR\", name=\"auc_pr\")])\n",
    "mod.summary()\n",
    "mod.fit(X_s, y, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
